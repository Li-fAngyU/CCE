{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the data_name and model_name at tmpargs class, then Run All. The result will save at final_result/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yf-auto/anaconda3/envs/lfytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class tmpargs():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data_dir = 'data/'\n",
    "        self.output_dir = 'final_result/'\n",
    "        self.data_name = 'LastFM'   # Change data_name Here.   \n",
    "        self.do_eval = None\n",
    "        self.ckp = 50\n",
    "        self.model_name = 'SASRec'  # Change model_name Here.  \n",
    "        self.hidden_size = 64\n",
    "        self.num_hidden_layers = 2\n",
    "        self.num_attention_heads = 2\n",
    "        self.hidden_act = 'gelu'\n",
    "        self.attention_probs_dropout_prob = 0.5\n",
    "        self.hidden_dropout_prob = 0.5\n",
    "        self.initializer_range = 0.02\n",
    "        self.max_seq_length = 50\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 256\n",
    "        self.epochs = 50\n",
    "        self.no_cuda = None\n",
    "        self.log_freq = 1\n",
    "        self.seed = 42\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_beta1 = 0.9\n",
    "        self.adam_beta2 = 0.999\n",
    "        self.gpu_id = 0\n",
    "        self.cuda_condition = torch.cuda.is_available() and not self.no_cuda\n",
    "        self.data_file = self.data_dir + self.data_name + '.txt'\n",
    "        self.sample_file = self.data_dir + self.data_name + '_sample.txt'\n",
    "        self.item2attribute = None\n",
    "        self.item_size = 104546+2\n",
    "        self.mask_id = 104546+1\n",
    "        self.attribute_size = 1 #没用到预训练模型\n",
    "        args_str = f'{self.model_name}-{self.data_name}-{self.ckp}'\n",
    "        self.log_file = os.path.join(self.output_dir, args_str + '.txt')\n",
    "        checkpoint = args_str + '.pt'\n",
    "        self.checkpoint_path = os.path.join(self.output_dir, checkpoint)\n",
    "        self.isfull = 0\n",
    "        self.sample_num =99\n",
    "        self.loss_type = None\n",
    "        self.writer = None\n",
    "        self.RQ3 = 1\n",
    "args = tmpargs()\n",
    "\n",
    "from utils import EarlyStopping, get_user_seqs\n",
    "user_seq, max_item, valid_rating_matrix, test_rating_matrix = \\\n",
    "        get_user_seqs(args.data_file)\n",
    "args.train_matrix = valid_rating_matrix\n",
    "args.item_size = max_item + 2\n",
    "args.mask_id = max_item + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user seq and sample seq\n",
    "user_seq,sample_seq = [], []\n",
    "with open(args.data_file,'r') as f:\n",
    "    for l in f:\n",
    "        user, items = l.strip().split(' ', 1)\n",
    "        items = items.split(' ')\n",
    "        items = [int(item) for item in items]\n",
    "        user_seq.append(items)\n",
    "\n",
    "with open(args.sample_file,'r') as f:\n",
    "    for l in f:\n",
    "        user, items = l.strip().split(' ', 1)\n",
    "        items = items.split(' ')\n",
    "        items = [int(item) for item in items]\n",
    "        sample_seq.append(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 315456\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from datasets import SASRecDataset\n",
    "from trainers import FinetuneTrainer\n",
    "from models import S3RecModel,GRU4Rec\n",
    "train_dataset = SASRecDataset(args, user_seq, data_type='train')\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.batch_size)\n",
    "\n",
    "eval_dataset = SASRecDataset(args, user_seq, data_type='valid')\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.batch_size)\n",
    "\n",
    "test_dataset = SASRecDataset(args, user_seq, test_neg_items=None, data_type='test')\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.batch_size)\n",
    "\n",
    "if args.model_name == \"GRU4Rec\":\n",
    "    model = GRU4Rec(args=args)\n",
    "else:\n",
    "    model = S3RecModel(args=args)\n",
    "\n",
    "trainer = FinetuneTrainer(model, train_dataloader, eval_dataloader,\n",
    "                            test_dataloader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from utils import recall_at_k, ndcg_k, get_metric, neg_sample\n",
    "\n",
    "import math\n",
    "\n",
    "def ndcg_at_k(rank, topk = 10):\n",
    "    metric = 0\n",
    "    tmp_rank = rank[rank<topk]\n",
    "    dcg_k = 0\n",
    "    for i in tmp_rank:\n",
    "        dcg_k += 1 / math.log(i+2,2)\n",
    "    return dcg_k / len(rank)\n",
    "\n",
    "def get_metric_at(time):\n",
    "    train = False\n",
    "    str_code = \"train\" if train else \"test\"\n",
    "    epoch = 0\n",
    "    dataloader = trainer.test_dataloader\n",
    "\n",
    "    rank = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # 0. batch_data will be sent into the device(GPU or cpu)\n",
    "        batch = tuple(t.to(trainer.device) for t in batch)\n",
    "        user_ids, input_ids, target_pos, target_neg, answers = batch\n",
    "        answers = target_pos[:,time]\n",
    "        input_ids = input_ids[answers!=0,:]\n",
    "        answers = answers[answers!=0]\n",
    "        \n",
    "        recommend_output = trainer.model.finetune(input_ids)\n",
    "        recommend_output = recommend_output[:, time, :]\n",
    "        rating_pred = trainer.predict_full(recommend_output)\n",
    "        rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "\n",
    "        tag = rating_pred[ np.arange(answers.shape[0]), answers.cpu().numpy() ]\n",
    "        \n",
    "        rating_pred.sort(axis=-1)\n",
    "        rating_pred = rating_pred[:,-1::-1]\n",
    "        \n",
    "        rank += list(np.where(rating_pred == tag.reshape(-1,1))[1])\n",
    "    rank = np.array(rank)\n",
    "    \n",
    "    metric = ndcg_at_k(rank)\n",
    "\n",
    "    print( sum(rank<100), round(sum(rank<100)/rank.shape[0],4), rank.shape[0] ,metric)\n",
    "    return sum(rank<100), round(sum(rank<100)/rank.shape[0],4), rank.shape[0] ,metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.0625 272 0.0011067279252352249\n",
      "20 0.0733 273 0.008350651881650253\n",
      "20 0.0719 278 0.006123444906547735\n",
      "29 0.1025 283 0.01276153248449223\n",
      "18 0.0621 290 0.006664139706151445\n",
      "26 0.0884 294 0.006963168131030963\n",
      "19 0.0644 295 0.0029198410716840205\n",
      "29 0.0963 301 0.0054758699711900385\n",
      "22 0.0717 307 0.00997747723836737\n",
      "25 0.0781 320 0.009379622501668539\n",
      "24 0.0734 327 0.011446666649365637\n",
      "30 0.0893 336 0.008255076233538938\n",
      "30 0.0872 344 0.014327110970376691\n",
      "33 0.0943 350 0.006791631966944512\n",
      "27 0.0763 354 0.01201505060232395\n",
      "49 0.1357 361 0.009380393782039729\n",
      "38 0.1027 370 0.010172767555851678\n",
      "33 0.0878 376 0.002475203611897322\n",
      "34 0.0876 388 0.009142194408564699\n",
      "36 0.0909 396 0.006934483684640193\n",
      "43 0.1059 406 0.01346723315844987\n",
      "42 0.1014 414 0.00920027023102921\n",
      "54 0.1286 420 0.012757585190211005\n",
      "43 0.1002 429 0.006154267413653194\n",
      "42 0.0966 435 0.0022988505747126436\n",
      "31 0.0697 445 0.008123878169766424\n",
      "45 0.0989 455 0.003287288890426595\n",
      "37 0.0786 471 0.005382603526915095\n",
      "37 0.076 487 0.005101018546149079\n",
      "55 0.1107 497 0.00492647710036095\n",
      "54 0.1053 513 0.01353537019903566\n",
      "50 0.0952 525 0.009468358507576166\n",
      "49 0.0894 548 0.0072912966229972545\n",
      "57 0.0997 572 0.00770987331511713\n",
      "66 0.1115 592 0.01322314329968739\n",
      "52 0.0846 615 0.008928887671095757\n",
      "80 0.1262 634 0.014207932414067547\n",
      "64 0.0983 651 0.009749226487775466\n",
      "68 0.1001 679 0.01222763450996758\n",
      "72 0.1014 710 0.011859314037705975\n",
      "80 0.1068 749 0.012497037336827091\n",
      "100 0.1269 788 0.009804941256843764\n",
      "80 0.0966 828 0.009670761788631712\n",
      "92 0.1041 884 0.012605173955742425\n",
      "102 0.1092 934 0.011085983935773123\n",
      "140 0.1383 1012 0.015336397394993744\n",
      "129 0.1183 1090 0.016057300451553246\n",
      "270 0.2477 1090 0.018900355700673048\n",
      "124 0.1138 1090 0.01463240671511876\n",
      "112 0.1027 1091 0.016121779664824108\n"
     ]
    }
   ],
   "source": [
    "file_name = 'final_result/GRU4Rec/' + args.data_name + '/GRU4Rec_CE-' + args.data_name + '-0.pt'\n",
    "model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "res = []\n",
    "for time in range(50):\n",
    "    rank, rate ,size, metric = get_metric_at(time)\n",
    "    res.append([rank, rate ,size, metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 0.1324 272 0.010734845541452495\n",
      "28 0.1026 273 0.003892932017534693\n",
      "39 0.1403 278 0.008398297259444819\n",
      "44 0.1555 283 0.01615143914675128\n",
      "39 0.1349 289 0.007640697288002788\n",
      "48 0.1633 294 0.013393799798283484\n",
      "39 0.1322 295 0.002674796021416569\n",
      "43 0.1433 300 0.005593670613648534\n",
      "46 0.1498 307 0.007514160870110381\n",
      "47 0.1469 320 0.014634150200977325\n",
      "56 0.1718 326 0.022788833285378843\n",
      "61 0.1815 336 0.015877403913536797\n",
      "57 0.1662 343 0.0182914947541215\n",
      "51 0.1461 349 0.009486287032325923\n",
      "65 0.1836 354 0.02311013215138795\n",
      "66 0.1828 361 0.017613903023879853\n",
      "75 0.2027 370 0.021885780351259744\n",
      "60 0.1596 376 0.008053015657105977\n",
      "67 0.1727 388 0.012984817486300688\n",
      "69 0.1742 396 0.004809752042406997\n",
      "71 0.1753 405 0.0209110453691573\n",
      "81 0.1957 414 0.016965281142556847\n",
      "69 0.1643 420 0.01572858115409202\n",
      "69 0.1612 428 0.009571991992574438\n",
      "74 0.1701 435 0.014333798464940522\n",
      "71 0.1599 444 0.008418907977762397\n",
      "65 0.1429 455 0.005827658331895501\n",
      "72 0.1529 471 0.007754025243743767\n",
      "77 0.1584 486 0.012235713382331263\n",
      "80 0.1613 496 0.01416973504394143\n",
      "92 0.1797 512 0.012443548883681228\n",
      "89 0.1695 525 0.01418928946785231\n",
      "82 0.1496 548 0.01014745350629645\n",
      "95 0.1661 572 0.01874068292220179\n",
      "99 0.1672 592 0.020520226951325146\n",
      "96 0.1561 615 0.015808962681851824\n",
      "111 0.1754 633 0.018965384360927297\n",
      "112 0.172 651 0.015182030929414097\n",
      "102 0.1502 679 0.011777775773102248\n",
      "117 0.1648 710 0.017665226957213814\n",
      "142 0.1898 748 0.022169707370922283\n",
      "152 0.1929 788 0.01991971145998242\n",
      "154 0.186 828 0.017254757775399664\n",
      "162 0.1835 883 0.014801189443128105\n",
      "152 0.1629 933 0.01613911142681293\n",
      "187 0.185 1011 0.02425305112731001\n",
      "210 0.1927 1090 0.02304601745983168\n",
      "176 0.1615 1090 0.012368925276101544\n",
      "165 0.1514 1090 0.01870260890804163\n",
      "133 0.122 1090 0.022835535671895536\n"
     ]
    }
   ],
   "source": [
    "file_name = 'final_result/GRU4Rec/' + args.data_name + '/GRU4Rec_PointwiseCE-' + args.data_name + '-0.pt'\n",
    "model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "res1 = []\n",
    "for time in range(50):\n",
    "    rank, rate ,size, metric = get_metric_at(time)\n",
    "    res1.append([rank, rate ,size, metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 0.136 272 0.007274284363085453\n",
      "30 0.1099 273 0.004830815225164762\n",
      "36 0.1295 278 0.0037616824012567545\n",
      "41 0.1449 283 0.016526799406714518\n",
      "35 0.1211 289 0.006165371806964448\n",
      "45 0.1531 294 0.008186053933886894\n",
      "33 0.1119 295 0.0023807379119331197\n",
      "45 0.15 300 0.011414941391229151\n",
      "53 0.1726 307 0.006980752222441165\n",
      "44 0.1375 320 0.016327923445830287\n",
      "54 0.1656 326 0.019460282074565755\n",
      "59 0.1756 336 0.01894072692908105\n",
      "56 0.1633 343 0.016651283189204467\n",
      "51 0.1461 349 0.014988659299522018\n",
      "63 0.178 354 0.02234622908473074\n",
      "74 0.205 361 0.019953625884519235\n",
      "71 0.1914 371 0.022221686645063108\n",
      "63 0.1676 376 0.007577994740441646\n",
      "72 0.1856 388 0.01487625887097236\n",
      "80 0.202 396 0.006921159100035949\n",
      "77 0.1901 405 0.020252424168589297\n",
      "76 0.1836 414 0.013074761790904322\n",
      "77 0.1833 420 0.017046689177051096\n",
      "70 0.1636 428 0.00850998049002817\n",
      "76 0.1747 435 0.010412711908551829\n",
      "74 0.1667 444 0.008384226120167914\n",
      "70 0.1538 455 0.008829898997356261\n",
      "72 0.1529 471 0.007919905610274076\n",
      "85 0.1749 486 0.013208732522438923\n",
      "80 0.1613 496 0.014968328242317195\n",
      "98 0.1914 512 0.016123194965488207\n",
      "91 0.1733 525 0.014830881069431498\n",
      "85 0.1551 548 0.013419321412360716\n",
      "93 0.1626 572 0.018315299026792395\n",
      "101 0.1706 592 0.019673940995162047\n",
      "114 0.1854 615 0.01807601344063186\n",
      "113 0.1785 633 0.01531751432891988\n",
      "113 0.1736 651 0.016275625530207193\n",
      "111 0.1635 679 0.012548747553125262\n",
      "115 0.162 710 0.017802429107574288\n",
      "150 0.2005 748 0.019310711864046082\n",
      "161 0.2043 788 0.020437783458649432\n",
      "141 0.1703 828 0.018040989007118348\n",
      "161 0.1823 883 0.017697385396422818\n",
      "163 0.1747 933 0.017655484629589803\n",
      "188 0.186 1011 0.024977228748755312\n",
      "219 0.2009 1090 0.02412076383870017\n",
      "167 0.1532 1090 0.014429541060563307\n",
      "168 0.1541 1090 0.018707880017737547\n",
      "138 0.1266 1090 0.023907767355655037\n"
     ]
    }
   ],
   "source": [
    "file_name = 'final_result/GRU4Rec/' + args.data_name + '/GRU4Rec_CE_ALL-' + args.data_name + '-0.pt'\n",
    "model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "res2 = []\n",
    "for time in range(50):\n",
    "    rank, rate ,size, metric = get_metric_at(time)\n",
    "    res2.append([rank, rate ,size, metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col = ['count','rank','num', 'metric']\n",
    "CE_result = pd.DataFrame(res,columns=col)\n",
    "CE_result.to_csv(f\"final_result/{args.data_name}_CE_result.csv\")\n",
    "\n",
    "BCEFT_result = pd.DataFrame(res1,columns=col)\n",
    "BCEFT_result.to_csv(f\"final_result/{args.data_name}_BCE_result.csv\")\n",
    "\n",
    "CEFT_result = pd.DataFrame(res2,columns=col)\n",
    "CEFT_result.to_csv(f\"final_result/{args.data_name}_CCE_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "101bfc27e1499e0150c1cdb694c49beeba39e9e278d1fc7a344c46ef141b0004"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('lfytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "101bfc27e1499e0150c1cdb694c49beeba39e9e278d1fc7a344c46ef141b0004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
